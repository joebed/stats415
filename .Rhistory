)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(x, train_errors, log = "x", xlab = "Cost", ylab="Error")
lines(x, train_errors, col="blue")
lines(x, test_errors, col="red")
lines(x, tune.out$performances$error, col="green")
tune.out
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs, gamma = c(.5,1,2,3,4)))
gamgam = tune.out$best.parameters$gamma
train_errors = list()
test_errors = list()
for (i in x){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "radial",
gamma = gamgam,
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(x, train_errors, log = "x", xlab = "Cost", ylab="Error")
lines(x, train_errors, col="blue")
lines(x, test_errors, col="red")
lines(x, tune.out$performances$error, col="green")
tune.out$performances
errors = for (i in nrow(tune.out$performances)){
if (tune.out$performances[i,2] == gamgam){
list = append(list, tune.out$performances[i,3])
}
}
errors = list()
errors = for (i in nrow(tune.out$performances)){
if (tune.out$performances[i,2] == gamgam){
list = append(list, tune.out$performances[i,3])
}
}
errors = for (i in seq(1,nrow(tune.out$performances))){
if (tune.out$performances[i,2] == gamgam){
list = append(list, tune.out$performances[i,3])
}
}
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs, gamma = c(.5,1,2,3,4)))
gamgam = tune.out$best.parameters$gamma
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs), gamma = gamgam)
train_errors = list()
test_errors = list()
for (i in x){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "radial",
gamma = gamgam,
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(x, train_errors, log = "x", xlab = "Cost", ylab="Error")
lines(x, train_errors, col="blue")
lines(x, test_errors, col="red")
lines(x, errors, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
plot(x, train_errors, log = "x", xlab = "Cost", ylab="Error")
lines(x, train_errors, col="blue")
lines(x, test_errors, col="red")
lines(x, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
tune.out$performances$error
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs, gamma = c(.5,1,2,3,4)))
gamgam = tune.out$best.parameters$gamma
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs), gamma = gamgam)
train_errors = list()
test_errors = list()
for (i in x){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "radial",
gamma = gamgam,
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(x, tune.out$performances$error, log = "x", xlab = "Cost", ylab="Error")
lines(x, train_errors, col="blue")
lines(x, test_errors, col="red")
lines(x, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
clear
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "polynomial", ranges = list(cost = costs, degree = c(.5,1,2,3,4)))
best_degree = tune.out$best.parameters$degree
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "polynomial", ranges = list(cost = costs), degree = best_degree)
train_errors = list()
test_errors = list()
for (i in x){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "polynomial",
degree = best_degree,
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(x, tune.out$performances$error, log = "x", xlab = "Cost", ylab="Error")
lines(x, train_errors, col="blue")
lines(x, test_errors, col="red")
lines(x, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
tune.out$performances
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs, gamma = c(.5,1,2,3,4)))
gamgam = tune.out$best.parameters$gamma
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs), gamma = gamgam)
train_errors = list()
test_errors = list()
for (i in costs){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "radial",
gamma = gamgam,
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(costs, tune.out$performances$error, log = "x", xlab = "Cost", ylab="Error")
lines(costs, train_errors, col="blue")
lines(costs, test_errors, col="red")
lines(costs, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "polynomial", ranges = list(cost = costs, degree = c(.5,1,2,3,4)))
best_degree = tune.out$best.parameters$degree
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "polynomial", ranges = list(cost = costs), degree = best_degree)
train_errors = list()
test_errors = list()
for (i in x){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "polynomial",
degree = best_degree,
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(costs, tune.out$performances$error, log = "x", xlab = "Cost", ylab="Error")
lines(costs, train_errors, col="blue")
lines(costs, test_errors, col="red")
lines(costs, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
tune.out$best.parameters
best_degree
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs, gamma = c(.5,1,2,3,4)))
gamgam = tune.out$best.parameters$gamma
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs), gamma = gamgam)
train_errors = list()
test_errors = list()
for (i in costs){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "radial",
gamma = gamgam,
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(costs, tune.out$performances$error, log = "x", xlab = "Cost", ylab="Error")
lines(costs, train_errors, col="blue")
lines(costs, test_errors, col="red")
lines(costs, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
View(train_errors)
View(test_errors)
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs, gamma = c(.01, .1,.5,1,2,3,4,8)))
gamgam = tune.out$best.parameters$gamma
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs), gamma = gamgam)
train_errors = list()
test_errors = list()
for (i in costs){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "radial",
gamma = gamgam,
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(costs, tune.out$performances$error, log = "x", xlab = "Cost", ylab="Error")
lines(costs, train_errors, col="blue")
lines(costs, test_errors, col="red")
lines(costs, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "polynomial", ranges = list(cost = costs, degree = c(.5,1,2,3,4)))
best_degree = tune.out$best.parameters$degree
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "polynomial", ranges = list(cost = costs), degree = best_degree)
train_errors = list()
test_errors = list()
for (i in costs){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "polynomial",
degree = best_degree,
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(costs, tune.out$performances$error, log = "x", xlab = "Cost", ylab="Error")
lines(costs, train_errors, col="blue")
lines(costs, test_errors, col="red")
lines(costs, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
help("svm")
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(e1071)
crabs = MASS::crabs
set.seed(6789)
train.bm = sample(50, 40)
train.fm = sample(50, 40) + 50
train.om = sample(50, 40) + 100
train.of = sample(50, 40) + 150
train = c(train.bm, train.fm, train.om, train.of)
test = seq(200)[-train]
crabs = crabs[,-c(2,3)]
costs = seq(10^seq(-4,2))
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "linear", ranges = list(cost = c(.0001, .001, .01, .1, 1, 10, 100)))
train_errors = list()
test_errors = list()
for (i in costs){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "linear",
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(costs, train_errors, log = "x", xlab = "Cost", ylab="Error")
lines(costs, train_errors, col="blue")
lines(costs, test_errors, col="red")
lines(costs, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
plot(crabs$FL, crabs$CW, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
plot(crabs$CL, crabs$CW, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
plot(crabs$RW, crabs$BD, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "linear", ranges = list(cost = c(.0001, .001, .01, .1, 1, 10, 100)))
train_errors = list()
test_errors = list()
for (i in costs){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "linear",
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(costs, train_errors, log = "x", xlab = "Cost", ylab="Error")
lines(costs, train_errors, col="blue")
lines(costs, test_errors, col="red")
lines(costs, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
plot(crabs$FL, crabs$CW, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
plot(crabs$CL, crabs$CW, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
plot(crabs$RW, crabs$BD, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "linear", ranges = list(cost = c(.0001, .001, .01, .1, 1, 10, 100)))
train_errors = list()
test_errors = list()
for (i in costs){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "linear",
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(costs, train_errors, log = "x", xlab = "Cost", ylab="Error", main="Errors")
lines(costs, train_errors, col="blue")
lines(costs, test_errors, col="red")
lines(costs, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
plot(crabs$FL, crabs$CW, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
plot(crabs$CL, crabs$CW, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
plot(crabs$RW, crabs$BD, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
costs
library(MASS)
library(e1071)
crabs = MASS::crabs
set.seed(6789)
train.bm = sample(50, 40)
train.fm = sample(50, 40) + 50
train.om = sample(50, 40) + 100
train.of = sample(50, 40) + 150
train = c(train.bm, train.fm, train.om, train.of)
test = seq(200)[-train]
crabs = crabs[,-c(2,3)]
costs = 10^seq(-4,2)
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "linear", ranges = list(cost = c(.0001, .001, .01, .1, 1, 10, 100)))
train_errors = list()
test_errors = list()
for (i in costs){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "linear",
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(costs, train_errors, log = "x", xlab = "Cost", ylab="Error", main="Errors")
lines(costs, train_errors, col="blue")
lines(costs, test_errors, col="red")
lines(costs, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
plot(crabs$FL, crabs$CW, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
plot(crabs$CL, crabs$CW, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
plot(crabs$RW, crabs$BD, col = crabs$sp)
legend("topleft", legend=c("Species B", "Species O"), pch=c(1), col=c("black", "red"))
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs, gamma = c(.01, .1,.5,1,2,3,4,8)))
gamgam = tune.out$best.parameters$gamma
tune.out = tune(svm, sp ~ ., data = crabs, kernel = "radial", ranges = list(cost = costs), gamma = gamgam)
train_errors = list()
test_errors = list()
for (i in costs){
svmfit = svm(
sp ~ .,
data = crabs[train,],
kernel = "radial",
gamma = gamgam,
scale = FALSE,
cost = i
)
svm.predict = predict(svmfit, crabs)
train_errors = append(train_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[train]))
test_errors = append(test_errors, mean(ifelse(svm.predict != crabs$sp, 1, 0)[test]))
}
plot(costs, tune.out$performances$error, log = "x", xlab = "Cost", ylab="Error")
lines(costs, train_errors, col="blue")
lines(costs, test_errors, col="red")
lines(costs, tune.out$performances$error, col="green")
legend("topright", legend=c("Test Error", "Train Error", "CV Error"), lty=1, col=c("red","blue", "green"))
View(crabs)
help(runif)
knitr::opts_chunk$set(echo = TRUE)
#Generate data
set.seed(123)
randoms = runif(100)
rm train
rm(train)
randoms
#Generate data
set.seed(123)
randoms = runif(100)
help(dinversegamma)
help(dinvgamma)
help(invgamma)
help(gamma)
help(dgamma)
#Generate data
set.seed(123)
lambdas = rgamma(100, shape = 2, scale = 5)
help(poisson)
help(dpoisson)
help(dpois)
#Generate data
set.seed(123)
lambdas = rgamma(100, shape = 2, scale = 5)
vals = list()
for (i in seq(100))
vals = append(vals, rpois(10, lambda = lambdas[i]))
#Generate data
set.seed(123)
lambdas = rgamma(100, shape = 2, scale = 5)
vals = list()
for (i in seq(100))
vals = append(vals, rpois(10, lambda = lambdas[i]))
ex = average(vals)
#Generate data
set.seed(123)
lambdas = rgamma(100, shape = 2, scale = 5)
vals = list()
for (i in seq(100))
vals = append(vals, rpois(10, lambda = lambdas[i]))
ex = avg(vals)
#Generate data
set.seed(123)
lambdas = rgamma(100, shape = 2, scale = 5)
vals = list()
for (i in seq(100))
vals = append(vals, rpois(10, lambda = lambdas[i]))
ex = mean(vals)
#Generate data
set.seed(123)
lambdas = rgamma(100, shape = 2, scale = 5)
vals = list()
for (i in seq(100))
vals = append(vals, rpois(10, lambda = lambdas[i]))
ex = mean(mean(vals))
#Generate data
set.seed(123)
lambdas = rgamma(100, shape = 2, scale = 5)
vals = list()
for (i in seq(100))
vals = append(vals, rpois(10, lambda = lambdas[i]))
data = df(vals)
#Generate data
set.seed(123)
lambdas = rgamma(100, shape = 2, scale = 5)
vals = list()
for (i in seq(100))
vals = append(vals, list(rpois(10, lambda = lambdas[i])))
View(vals)
help(df)
help("data.frame")
#Generate data
set.seed(123)
lambdas = rgamma(100, shape = 2, scale = 5)
vals = list()
for (i in seq(100))
vals = append(vals, list(rpois(10, lambda = lambdas[i])))
dat = data.frame()
#Generate data
set.seed(123)
lambdas = list(rgamma(100, shape = 2, scale = 5))
vals = list()
for (i in seq(100))
vals = append(vals, list(rpois(10, lambda = lambdas[i])))
rm ex
rm(ex)
#Generate data
set.seed(123)
lambdas = list(rgamma(100, shape = 2, scale = 5))
vals = list()
for (i in seq(100))
vals = append(vals, list(rpois(10, lambda = lambdas[i])))
#Generate data
set.seed(123)
lambdas = rgamma(100, shape = 2, scale = 5)
vals = list()
for (i in seq(100))
vals = append(vals, list(rpois(10, lambda = lambdas[i])))
dat = data.frame()
dat$lambda =
rm(list=ls())
git status
setwd("junior/stats415/final_project")
getwd()
train = csv.read(train_data)
train = read.csv(train_data)
train = read.csv(train_data.csv)
train = read.csv("train_data.csv")
test = read.csv("test_data.csv")
rm(list=ls())
